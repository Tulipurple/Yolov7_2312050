{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbe072a-b803-4842-b928-ce01640fe124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference for ONNX model\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "cuda = True\n",
    "w = \"yolov7-tiny.onnx\"\n",
    "#img = cv2.imread('horses.jpg')  # image-based execute!\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import random\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict,namedtuple\n",
    "\n",
    "providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if cuda else ['CPUExecutionProvider'] #['AzureExecutionProvider', 'CPUExecutionProvider'] if cuda else ['CPUExecutionProvider']\n",
    "session = ort.InferenceSession(w, providers=providers)\n",
    "\n",
    "tf.compat.disable_v2_behavior()\n",
    "with tf.compat.Session() as sess:\n",
    "    x = tf.compat.placeholder(tf.float32, [2])\n",
    "    x2 = tf.square(x)\n",
    "    print(sess.run(x2, feed_dict={x: [2, 3]}))\n",
    "    # [4. 9.]\n",
    "\n",
    "#print(\"00000\")\n",
    "\n",
    "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleup=True, stride=32):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = im.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return im, r, (dw, dh)\n",
    "\n",
    "names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', \n",
    "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', \n",
    "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', \n",
    "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', \n",
    "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', \n",
    "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', \n",
    "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', \n",
    "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', \n",
    "         'hair drier', 'toothbrush']\n",
    "colors = {name:[random.randint(0, 255) for _ in range(3)] for i,name in enumerate(names)}\n",
    "\n",
    "webcam = cv2.VideoCapture(0)\n",
    "webcam.set(3, 640)\n",
    "webcam.set(4, 480)\n",
    "ratio_factor = 0.9\n",
    "\n",
    "if not webcam.isOpened():\n",
    "    print(\"Could not open webcam\")\n",
    "    exit()\n",
    "\n",
    "while webcam.isOpened():\n",
    "    status, img = webcam.read()\n",
    "    \n",
    "    height, width = img.shape[:2]\n",
    "    img = cv2.resize(img, (1280, 720))\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #cv2.imshow(\"original\",img)\n",
    "    \n",
    "\n",
    "    image = img.copy()\n",
    "    image, ratio, dwdh = letterbox(image, auto=False)\n",
    "    image = image.transpose((2, 0, 1))\n",
    "    image = np.expand_dims(image, 0)\n",
    "    image = np.ascontiguousarray(image)\n",
    "\n",
    "    #print(\"11111\")\n",
    "\n",
    "    im = image.astype(np.float32)\n",
    "    im /= 255\n",
    "    im.shape\n",
    "\n",
    "    outname = [i.name for i in session.get_outputs()]\n",
    "    outname\n",
    "\n",
    "    inname = [i.name for i in session.get_inputs()]\n",
    "   # inname\n",
    "\n",
    "    inp = {inname[0]:im}\n",
    "\n",
    "    # ONNX inference\n",
    "    outputs = session.run(outname, inp)[0]\n",
    "    #outputs\n",
    "\n",
    "    ori_images = [img.copy()]\n",
    "\n",
    "    for i,(batch_id,x0,y0,x1,y1,cls_id,score) in enumerate(outputs):\n",
    "        image = ori_images[int(batch_id)]\n",
    "        box = np.array([x0,y0,x1,y1])\n",
    "        box -= np.array(dwdh*2)\n",
    "        box /= ratio\n",
    "        box = box.round().astype(np.int32).tolist()\n",
    "        cls_id = int(cls_id)\n",
    "        score = round(float(score),3)\n",
    "        name = names[cls_id]\n",
    "        color = colors[name]\n",
    "        name += ' '+str(score)\n",
    "        cv2.rectangle(image,box[:2],box[2:],color,2)\n",
    "        cv2.putText(image,name,(box[0], box[1] - 2),cv2.FONT_HERSHEY_SIMPLEX,0.75,[225, 255, 255],thickness=2)  \n",
    "\n",
    "    print('[INFO] draw all detected boxes by Prof. Kim....!')    #<===== 여기에 여러분들의 학번이 표시되도록 합니다.\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # PIL image --> opencv image Mat buffer\n",
    "    \n",
    "    if status:\n",
    "        cv2.imshow(\"results\",image)\n",
    "    \n",
    "    #if status:\n",
    "    #    img=Image.fromarray(ori_images[0])\n",
    "    #    img.save('output.png')\n",
    "    #    img.show()\n",
    "    #    cv2.imshow(img)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8728968-7db5-428a-a52f-393198a7e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c32268-ba55-4358-94cb-2bb6a020b67d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
